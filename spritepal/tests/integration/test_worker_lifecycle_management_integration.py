"""
Integration tests for Worker Lifecycle Management.

These tests focus on preventing the specific bugs that were fixed:
- Thread leaks from improper worker cleanup
- Signal connection leaks after worker destruction
- Memory leaks from workers not being garbage collected
- Concurrent worker creation/destruction issues
"""

from __future__ import annotations

import gc
import threading
import time
import weakref

import pytest
from PySide6.QtCore import QThread, Signal
from tests.infrastructure.qt_real_testing import (
    EventLoopHelper,
    MemoryHelper,
    QtTestCase,
)


class MockWorker(QThread):
    """Mock worker for testing lifecycle management."""

    finished_work = Signal()
    progress = Signal(int)
    error = Signal(str)

    def __init__(self, work_duration=100, parent=None):
        """Initialize mock worker.
        
        Args:
            work_duration: How long to simulate work (ms)
            parent: Parent object
        """
        super().__init__(parent)
        self.work_duration = work_duration
        self.stop_requested = False
        self.work_completed = False

    def run(self):
        """Simulate some work."""
        try:
            for i in range(10):
                if self.stop_requested:
                    break

                self.progress.emit(i * 10)
                self.msleep(self.work_duration // 10)

            if not self.stop_requested:
                self.work_completed = True
                self.finished_work.emit()
        except Exception as e:
            self.error.emit(str(e))

    def stop(self):
        """Request worker to stop."""
        self.stop_requested = True

    def cleanup(self):
        """Clean up worker resources."""
        self.stop()
        if self.isRunning():
            self.wait(1000)  # Wait up to 1 second

class WorkerManager:
    """Test worker manager for lifecycle testing."""

    def __init__(self):
        """Initialize worker manager."""
        self.active_workers: dict[str, MockWorker] = {}
        self.worker_history: list[str] = []

    def create_worker(self, worker_id: str, work_duration: int = 100) -> MockWorker:
        """Create and track a worker.
        
        Args:
            worker_id: Unique identifier for worker
            work_duration: Work duration in ms
            
        Returns:
            Created worker
        """
        # Clean up existing worker with same ID
        if worker_id in self.active_workers:
            self.cleanup_worker(worker_id)

        worker = MockWorker(work_duration)
        self.active_workers[worker_id] = worker
        self.worker_history.append(f"created_{worker_id}")

        return worker

    def cleanup_worker(self, worker_id: str) -> bool:
        """Clean up a specific worker.
        
        Args:
            worker_id: Worker to clean up
            
        Returns:
            True if worker was cleaned up
        """
        if worker_id not in self.active_workers:
            return False

        worker = self.active_workers[worker_id]

        # Disconnect all signals to prevent leaks
        try:
            worker.finished_work.disconnect()
            worker.progress.disconnect()
            worker.error.disconnect()
        except (RuntimeError, TypeError):
            # Signals might already be disconnected
            pass

        # Stop and wait for thread
        worker.cleanup()

        # Remove from tracking
        del self.active_workers[worker_id]
        self.worker_history.append(f"cleaned_{worker_id}")

        return True

    def cleanup_all_workers(self):
        """Clean up all active workers."""
        worker_ids = list(self.active_workers.keys())
        for worker_id in worker_ids:
            self.cleanup_worker(worker_id)

    def get_active_worker_count(self) -> int:
        """Get count of active workers."""
        return len(self.active_workers)

@pytest.fixture
def worker_manager():
    """Create a worker manager for testing."""
    manager = WorkerManager()
    yield manager
    # Clean up all workers after test
    manager.cleanup_all_workers()

@pytest.mark.gui
@pytest.mark.integration
class TestWorkerLifecycleManagementIntegration(QtTestCase):
    """Integration tests for worker lifecycle management."""

    def test_basic_worker_lifecycle(self, worker_manager):
        """Test basic worker creation, execution, and cleanup."""
        # Create worker
        worker = worker_manager.create_worker("test_worker", 200)

        assert worker_manager.get_active_worker_count() == 1
        assert not worker.isRunning()

        # Start worker
        worker.start()
        assert worker.isRunning()

        # Wait for completion
        assert worker.wait(2000), "Worker did not finish within timeout"
        assert not worker.isRunning()
        assert worker.work_completed

        # Clean up
        assert worker_manager.cleanup_worker("test_worker")
        assert worker_manager.get_active_worker_count() == 0

    def test_worker_replacement_cleanup(self, worker_manager):
        """Test that creating worker with same ID cleans up previous one."""
        # Create first worker
        worker1 = worker_manager.create_worker("replaceable", 500)
        worker1_ref = weakref.ref(worker1)

        worker1.start()
        EventLoopHelper.process_events(50)  # Let it start

        assert worker1.isRunning()

        # Create replacement worker with same ID
        worker2 = worker_manager.create_worker("replaceable", 100)

        # First worker should be cleaned up
        EventLoopHelper.process_events(100)
        gc.collect()

        # Only one active worker
        assert worker_manager.get_active_worker_count() == 1
        assert worker_manager.active_workers["replaceable"] is worker2

        # Old worker should eventually be garbage collected
        for _ in range(10):
            gc.collect()
            EventLoopHelper.process_events(50)
            if worker1_ref() is None:
                break

        # First worker should be cleaned up from memory
        assert worker1_ref() is None, "Old worker was not garbage collected"

    def test_concurrent_worker_cleanup_safety(self, worker_manager):
        """Test thread safety of concurrent worker operations."""
        # Create multiple workers
        worker_ids = [f"worker_{i}" for i in range(5)]

        workers = []
        for worker_id in worker_ids:
            worker = worker_manager.create_worker(worker_id, 300)
            workers.append(worker)
            worker.start()

        assert worker_manager.get_active_worker_count() == 5

        # All should be running
        for worker in workers:
            assert worker.isRunning()

        # Clean up all concurrently (simulates window closing)
        worker_manager.cleanup_all_workers()

        # All should be stopped
        for worker in workers:
            assert not worker.isRunning()

        assert worker_manager.get_active_worker_count() == 0

    def test_signal_disconnection_prevents_leaks(self, worker_manager):
        """Test that signal disconnection prevents memory leaks."""
        signal_calls = []

        # Create worker and connect signals
        worker = worker_manager.create_worker("signal_test", 100)

        worker.progress.connect(lambda val: signal_calls.append(f"progress_{val}"))
        worker.finished_work.connect(lambda: signal_calls.append("finished"))
        worker.error.connect(lambda msg: signal_calls.append(f"error_{msg}"))

        # Start and let it complete
        worker.start()
        worker.wait(2000)

        initial_signal_count = len(signal_calls)
        assert initial_signal_count > 0, "No signals were received"

        # Clean up worker
        worker_manager.cleanup_worker("signal_test")

        # Try to trigger signals after cleanup (should not add to signal_calls)
        try:
            worker.progress.emit(999)
            worker.finished_work.emit()
        except RuntimeError:
            # Expected - worker is cleaned up
            pass

        EventLoopHelper.process_events(100)

        # Signal count should not have increased
        assert len(signal_calls) == initial_signal_count, "Signals were not properly disconnected"

    def test_memory_leak_prevention(self, worker_manager):
        """Test that worker cleanup prevents memory leaks."""
        initial_thread_count = threading.active_count()

        with MemoryHelper.assert_no_leak(MockWorker, max_increase=1):
            # Create and destroy many workers
            for i in range(10):
                worker_id = f"temp_worker_{i}"
                worker = worker_manager.create_worker(worker_id, 50)

                # Start and complete work
                worker.start()
                worker.wait(1000)

                # Clean up immediately
                worker_manager.cleanup_worker(worker_id)

            # Force garbage collection
            gc.collect()
            EventLoopHelper.process_events(100)
            gc.collect()

        # Thread count should not have grown excessively
        final_thread_count = threading.active_count()
        thread_increase = final_thread_count - initial_thread_count

        assert thread_increase <= 2, f"Thread count increased by {thread_increase}, possible thread leak"

    def test_worker_interruption_handling(self, worker_manager):
        """Test proper handling of worker interruption."""
        # Create long-running worker
        worker = worker_manager.create_worker("long_worker", 2000)

        worker.start()
        EventLoopHelper.process_events(100)  # Let it start

        assert worker.isRunning()

        # Request stop
        worker.stop()

        # Should stop within reasonable time
        start_time = time.time()
        result = worker.wait(1000)
        stop_time = time.time() - start_time

        assert result, "Worker did not stop within timeout"
        assert stop_time < 0.5, f"Worker took {stop_time:.2f}s to stop"
        assert not worker.isRunning()
        assert not worker.work_completed  # Should not complete if stopped early

    def test_cleanup_during_execution(self, worker_manager):
        """Test cleanup of worker during execution."""
        progress_values = []

        worker = worker_manager.create_worker("executing_worker", 500)
        worker.progress.connect(progress_values.append)

        worker.start()
        EventLoopHelper.process_events(100)  # Let some progress happen

        # Clean up while running
        assert worker_manager.cleanup_worker("executing_worker")

        # Should have received some progress signals
        assert len(progress_values) > 0

        # Worker should be stopped
        assert not worker.isRunning()

    @pytest.mark.slow
    def test_massive_worker_lifecycle_stress(self, worker_manager):
        """Stress test with many workers to detect leaks."""
        import os

        import psutil

        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        initial_threads = threading.active_count()

        # Create and destroy many workers rapidly
        for batch in range(10):  # 10 batches of 10 workers each
            # Create batch of workers
            batch_workers = []
            for i in range(10):
                worker_id = f"stress_batch_{batch}_worker_{i}"
                worker = worker_manager.create_worker(worker_id, 50)
                batch_workers.append((worker_id, worker))
                worker.start()

            # Wait for completion
            for worker_id, worker in batch_workers:
                worker.wait(500)

            # Clean up batch
            for worker_id, _ in batch_workers:
                worker_manager.cleanup_worker(worker_id)

            # Force cleanup between batches
            gc.collect()
            EventLoopHelper.process_events(50)

        # Final cleanup
        gc.collect()
        EventLoopHelper.process_events(100)
        gc.collect()

        final_memory = process.memory_info().rss / 1024 / 1024  # MB
        final_threads = threading.active_count()

        memory_increase = final_memory - initial_memory
        thread_increase = final_threads - initial_threads

        # Memory and thread usage should remain reasonable
        assert memory_increase < 50, f"Memory increased by {memory_increase:.1f} MB"
        assert thread_increase <= 3, f"Thread count increased by {thread_increase}"

@pytest.mark.gui
@pytest.mark.integration
class TestWorkerManagerPatterns(QtTestCase):
    """Test common worker manager patterns."""

    def test_singleton_worker_pattern(self, worker_manager):
        """Test singleton worker pattern (one worker at a time)."""
        class SingletonWorkerManager:
            def __init__(self):
                self.current_worker = None
                self.worker_count = 0

            def start_work(self, work_duration=100):
                # Clean up existing worker
                if self.current_worker:
                    self.current_worker.cleanup()
                    self.current_worker = None

                # Create new worker
                self.current_worker = MockWorker(work_duration)
                self.worker_count += 1
                self.current_worker.start()

            def stop_work(self):
                if self.current_worker:
                    self.current_worker.cleanup()
                    self.current_worker = None

            def is_working(self):
                return self.current_worker and self.current_worker.isRunning()

        manager = SingletonWorkerManager()

        # Start first work
        manager.start_work(200)
        assert manager.is_working()

        # Start second work (should replace first)
        manager.start_work(100)
        assert manager.is_working()
        assert manager.worker_count == 2  # Two workers created total

        # Stop work
        manager.stop_work()
        assert not manager.is_working()

    def test_worker_pool_pattern(self, worker_manager):
        """Test worker pool pattern (limited concurrent workers)."""
        class WorkerPool:
            def __init__(self, max_workers=3):
                self.max_workers = max_workers
                self.active_workers = {}
                self.next_id = 0

            def submit_work(self, work_duration=100):
                if len(self.active_workers) >= self.max_workers:
                    return None  # Pool full

                worker_id = f"pool_worker_{self.next_id}"
                self.next_id += 1

                worker = MockWorker(work_duration)
                worker.finished_work.connect(lambda: self._on_worker_finished(worker_id))

                self.active_workers[worker_id] = worker
                worker.start()
                return worker_id

            def _on_worker_finished(self, worker_id):
                if worker_id in self.active_workers:
                    self.active_workers[worker_id].cleanup()
                    del self.active_workers[worker_id]

            def get_active_count(self):
                return len(self.active_workers)

            def cleanup_all(self):
                for worker in self.active_workers.values():
                    worker.cleanup()
                self.active_workers.clear()

        pool = WorkerPool(max_workers=2)

        # Submit work up to limit
        job1 = pool.submit_work(300)
        job2 = pool.submit_work(300)
        assert job1 is not None
        assert job2 is not None
        assert pool.get_active_count() == 2

        # Pool should be full
        job3 = pool.submit_work(100)
        assert job3 is None

        # Wait for completion
        EventLoopHelper.process_events(500)

        # Workers should auto-cleanup when finished
        # (In real test we'd wait for signals, here we'll cleanup manually)
        pool.cleanup_all()
        assert pool.get_active_count() == 0

@pytest.mark.headless
@pytest.mark.integration
class TestWorkerLifecycleHeadlessIntegration:
    """Headless integration tests for worker lifecycle patterns."""

    def test_headless_cleanup_logic(self):
        """Test cleanup logic without Qt dependencies."""
        class MockWorkerState:
            def __init__(self, worker_id):
                self.worker_id = worker_id
                self.is_running = False
                self.is_stopped = False
                self.signal_connected = True

            def start(self):
                self.is_running = True

            def stop(self):
                self.is_stopped = True
                self.is_running = False

            def disconnect_signals(self):
                self.signal_connected = False

        class MockLifecycleManager:
            def __init__(self):
                self.workers = {}
                self.cleanup_log = []

            def create_worker(self, worker_id):
                if worker_id in self.workers:
                    self.cleanup_worker(worker_id)

                worker = MockWorkerState(worker_id)
                self.workers[worker_id] = worker
                return worker

            def cleanup_worker(self, worker_id):
                if worker_id not in self.workers:
                    return False

                worker = self.workers[worker_id]

                # Cleanup sequence
                if worker.is_running:
                    worker.stop()
                    self.cleanup_log.append(f"stopped_{worker_id}")

                worker.disconnect_signals()
                self.cleanup_log.append(f"disconnected_{worker_id}")

                del self.workers[worker_id]
                self.cleanup_log.append(f"removed_{worker_id}")

                return True

            def cleanup_all(self):
                worker_ids = list(self.workers.keys())
                for worker_id in worker_ids:
                    self.cleanup_worker(worker_id)

        manager = MockLifecycleManager()

        # Create and start workers
        worker1 = manager.create_worker("test1")
        worker2 = manager.create_worker("test2")

        worker1.start()
        worker2.start()

        assert len(manager.workers) == 2
        assert all(w.is_running for w in manager.workers.values())

        # Clean up all
        manager.cleanup_all()

        assert len(manager.workers) == 0
        assert "stopped_test1" in manager.cleanup_log
        assert "disconnected_test2" in manager.cleanup_log
        assert len(manager.cleanup_log) == 6  # 3 steps * 2 workers

    def test_headless_signal_leak_prevention_logic(self):
        """Test signal leak prevention logic."""
        class MockSignalConnection:
            def __init__(self, signal_name):
                self.signal_name = signal_name
                self.connected_slots = []
                self.is_connected = True

            def connect(self, slot):
                if self.is_connected:
                    self.connected_slots.append(slot)

            def disconnect(self, slot=None):
                if slot is None:
                    self.connected_slots.clear()
                elif slot in self.connected_slots:
                    self.connected_slots.remove(slot)
                self.is_connected = False

        class MockSignalManager:
            def __init__(self):
                self.signals = {
                    'finished': MockSignalConnection('finished'),
                    'progress': MockSignalConnection('progress'),
                    'error': MockSignalConnection('error'),
                }
                self.slots = []

            def connect_all_signals(self):
                for signal in self.signals.values():
                    slot = f"slot_for_{signal.signal_name}"
                    signal.connect(slot)
                    self.slots.append(slot)

            def disconnect_all_signals(self):
                for signal in self.signals.values():
                    signal.disconnect()

            def get_connected_slot_count(self):
                return sum(len(s.connected_slots) for s in self.signals.values())

        manager = MockSignalManager()

        # Connect signals
        manager.connect_all_signals()
        assert manager.get_connected_slot_count() == 3

        # Disconnect all
        manager.disconnect_all_signals()
        assert manager.get_connected_slot_count() == 0

        # Verify disconnection prevents leaks
        all_disconnected = all(not s.is_connected for s in manager.signals.values())
        assert all_disconnected

    def test_headless_concurrent_cleanup_safety_logic(self):
        """Test concurrent cleanup safety logic."""
        import threading

        class ThreadSafeWorkerRegistry:
            def __init__(self):
                self.workers = {}
                self.lock = threading.Lock()
                self.cleanup_count = 0

            def register_worker(self, worker_id, worker):
                with self.lock:
                    self.workers[worker_id] = worker

            def cleanup_worker(self, worker_id):
                with self.lock:
                    if worker_id in self.workers:
                        # Simulate cleanup operations
                        worker = self.workers[worker_id]
                        worker['cleaned'] = True
                        del self.workers[worker_id]
                        self.cleanup_count += 1
                        return True
                return False

            def get_worker_count(self):
                with self.lock:
                    return len(self.workers)

            def cleanup_all(self):
                with self.lock:
                    worker_ids = list(self.workers.keys())
                    for worker_id in worker_ids:
                        self.cleanup_worker(worker_id)

        registry = ThreadSafeWorkerRegistry()

        # Register workers
        for i in range(10):
            registry.register_worker(f"worker_{i}", {'id': i, 'cleaned': False})

        assert registry.get_worker_count() == 10

        # Simulate concurrent cleanup from multiple threads
        def cleanup_batch(start, end):
            for i in range(start, end):
                registry.cleanup_worker(f"worker_{i}")

        threads = []
        for i in range(0, 10, 2):  # Create 5 threads, each cleaning 2 workers
            thread = threading.Thread(target=cleanup_batch, args=(i, i + 2))
            threads.append(thread)
            thread.start()

        # Wait for all threads to complete
        for thread in threads:
            thread.join()

        # All workers should be cleaned up
        assert registry.get_worker_count() == 0
        assert registry.cleanup_count == 10
