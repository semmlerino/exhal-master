[pytest]
# SpritePal-specific pytest configuration

testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Add spritepal to Python path
pythonpath = .

# Show extra test summary info
addopts = 
    -v
    --tb=short
    --strict-markers
    --disable-warnings
    -p no:xvfb
    
# Qt-specific settings for pytest-qt
qt_api = pyside6
qt_default_raise = true
qt_wait_timeout = 10000
# qt_qpa_platform = offscreen  # Disabled to allow GUI tests when needed

# Qt test filtering
filterwarnings =
    ignore::DeprecationWarning:PySide6.*
    ignore::RuntimeWarning:PySide6.*
    ignore:.*QApplication.*:RuntimeWarning
    ignore:.*QThread.*:RuntimeWarning

# Xvfb configuration disabled for WSL compatibility
# xvfb_width = 1280
# xvfb_height = 1024
# xvfb_colordepth = 24
# xvfb_args = -screen 0 1280x1024x24 -ac +extension GLX

# Test collection settings
norecursedirs = .git __pycache__ *.egg-info .pytest_cache ui

# Environment-specific timeout configuration
# Increase timeouts in CI/headless environments for stability
# Set PYTEST_TIMEOUT_MULTIPLIER=2 for even longer timeouts in problematic environments

# Custom markers
markers =
    # Environment-specific markers for comprehensive environment detection
    ci_safe: Tests safe for CI environments (compatible with all CI systems)
    display_required: Tests that explicitly require a display (will be skipped in headless)
    headless_compatible: Tests that work in both headless and display environments
    xvfb_compatible: Tests that can use xvfb for virtual display
    wsl_compatible: Tests that work properly on WSL/WSL2
    docker_compatible: Tests that work in Docker containers
    # Execution Environment Markers (Primary Categories)
    gui: GUI tests requiring display/X11 environment (may be skipped in headless)
    headless: Tests that can run without display (safe for CI/headless environments)
    mock_only: Tests using only mocked components (fastest, most reliable)
    
    # Test Type Markers
    unit: Unit tests (fast, isolated, no external dependencies)
    integration: Integration tests (may require files, databases, services)
    benchmark: Performance benchmarking tests
    performance: Performance tests
    stress: Stress/load testing
    slow: Slow tests (>1s execution time)
    
    # Qt Component Markers
    qt_real: Tests using real Qt components (widgets, dialogs, etc.)
    qt_mock: Tests using mocked Qt components
    qt_app: Tests requiring QApplication instance
    no_qt: Tests with no Qt dependencies whatsoever
    
    # Threading and Concurrency Markers
    thread_safety: Thread safety tests
    timer: Tests involving QTimer functionality  
    worker_threads: Tests using worker threads
    signals_slots: Tests focused on Qt signal/slot mechanisms
    
    # Manager and Infrastructure Markers
    manager: Tests focused on testing manager classes
    mock_managers: Tests using mocked managers
    real_managers: Tests using real manager instances
    no_manager_setup: Tests that skip manager initialization
    isolated_managers: Tests requiring fresh manager instances (slow)
    
    # Data and Resource Markers
    rom_data: Tests requiring ROM files or data
    file_io: Tests involving file operations
    cache: Tests involving caching mechanisms
    memory: Memory management tests
    
    # Dialog and UI Markers
    dialog: Tests involving dialogs
    mock_dialogs: Tests that mock dialog exec() methods
    widget: Tests involving widgets
    preview: Tests involving preview components
    
    # Stability and Quality Markers
    stability: Stability/regression tests
    phase1_fixes: Tests validating Phase 1 critical fixes
    critical: Critical functionality tests that must always pass
    
    # Execution Control Markers
    serial: Tests that must run in serial (not parallel)
    parallel_safe: Tests confirmed safe for parallel execution
    process_pool: Tests using process pools that need serial execution
    singleton: Tests manipulating singletons that conflict in parallel
    qt_application: Tests managing QApplication that conflict in parallel
    
    # Development and Debug Markers
    debug: Debug-related tests
    validation: Validation and verification tests
    fixture_test: Tests validating test fixtures themselves
    infrastructure: Tests of testing infrastructure
    
    # Special Configuration Markers
    timeout: Set custom timeout for test
    no_xvfb: Skip xvfb for specific tests
    qt_no_exception_capture: Disable Qt exception capture for specific tests
    
    # Platform and Environment Markers
    wsl: Tests that behave differently on WSL
    linux_only: Tests that only run on Linux
    windows_only: Tests that only run on Windows
    
    # Additional markers
    asyncio: Tests using asyncio functionality
    qt_integration: Qt integration tests
    no_gui: Tests that should not use GUI components
    real_qt: Tests using real Qt components (alias for qt_real)
    
    # Missing markers found in test files
    leaks_references: Tests that check for memory leaks and reference counting
    mock: General mocking tests 
    mock_gui: Tests using mocked GUI components
    real_hal: Tests using real HAL (Hardware Abstraction Layer) components
    requires_rom: Tests that require ROM file data to run
    slow_pypy: Tests that are slow specifically on PyPy interpreter
    valgrind_error: Tests that may trigger valgrind errors (memory debugging)
    requires_display: Tests that require a display to run (same as display_required)

# Environment-specific pytest configuration profiles
# These can be activated with environment variables:
#
# For CI environments:
#   export PYTEST_CURRENT_TEST=1 
#   export QT_QPA_PLATFORM=offscreen
#   pytest -m "headless or mock_only" --tb=line -x
#
# For headless testing with xvfb:  
#   export DISPLAY=:99
#   xvfb-run -a pytest -m "gui or headless" --tb=short
#
# For local development with display:
#   pytest -m "not slow" --tb=short -v
#
# For comprehensive testing (all environments):
#   pytest --tb=short -v --maxfail=10